{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitattributes',\n",
       " '.gitignore',\n",
       " '.vscode',\n",
       " 'data',\n",
       " 'motivation.md',\n",
       " 'README.md',\n",
       " 'scripts']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/luism/Documents/Programacion_local/Clase/4o Año/Descubrimiento Datos Complejos/DCDC-Proyecto-Stocks\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_files = os.listdir(\"data/processed\")\n",
    "processed_data_files = [os.path.join(\"data/processed\", file) for file in processed_data_files if not file.endswith(\".md\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_agg_file(file_to_process:str,subset:float=1.0) -> pd.DataFrame:\n",
    "    \"\"\"Proccess a file and aggregate it by its dates\n",
    "\n",
    "    Args:\n",
    "        file_to_process (str): Path to csv file to process\n",
    "        subset (float, optional): Percentage of data to use. Defaults to 1.0.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame | None: DataFrame with aggregated data or None if error\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    start_file = time.time()\n",
    "    try:\n",
    "        print(datetime.now().strftime('%H:%M:%S'), \"- Loading file\", file_to_process)\n",
    "        p = pd.read_csv(file_to_process)\n",
    "\n",
    "        if \"index\" in p.columns:\n",
    "            p.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "        possible_date_col = [\"date\", \"article_date\", \"post_date\", \"Date\", \"created_at\",]\n",
    "        date_col = None\n",
    "        for col in possible_date_col:\n",
    "            if col in p.columns:\n",
    "                date_col = col\n",
    "                break\n",
    "\n",
    "        if date_col is None:\n",
    "            raise ValueError(\"No date column found\")\n",
    "\n",
    "        print(\"Date column:\", date_col)\n",
    "        p.rename(columns={date_col: \"date\"}, inplace=True)\n",
    "        date_col = \"date\"\n",
    "        p[date_col] = pd.to_datetime(p[date_col],utc=True).dt.date\n",
    "\n",
    "        p = p.sort_values(date_col)\n",
    "\n",
    "        if subset < 1.0:\n",
    "            p = p.iloc[:int(len(p) * subset)]\n",
    "        \n",
    "\n",
    "        # Group by date and aggregate\n",
    "        p.groupby(date_col).agg(list).reset_index()\n",
    "        print(f\"File {file_to_process} loaded in {time.time() - start_file:.2f} seconds\")\n",
    "        return p\n",
    "    except Exception as e:\n",
    "        print(\"Error loading file\", file_to_process)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "23:25:58 - Loading file data/processed\\analyst_ratings_cleaned-1.csv\n",
      "Date column: date\n",
      "File data/processed\\analyst_ratings_cleaned-1.csv loaded in 5.43 seconds\n",
      "Concatinating data\n",
      "Done!\n",
      "\n",
      "\n",
      "23:26:04 - Loading file data/processed\\analyst_ratings_cleaned-2.csv\n",
      "Date column: date\n",
      "File data/processed\\analyst_ratings_cleaned-2.csv loaded in 5.53 seconds\n",
      "Concatinating data\n",
      "Done!\n",
      "\n",
      "\n",
      "23:26:09 - Loading file data/processed\\david_check_stock_news_processed.csv\n",
      "Date column: date\n",
      "File data/processed\\david_check_stock_news_processed.csv loaded in 2.19 seconds\n",
      "Concatinating data\n",
      "Done!\n",
      "\n",
      "\n",
      "23:26:11 - Loading file data/processed\\ic-fspml_stock_news_sentiment_processed.csv\n",
      "Date column: article_date\n",
      "File data/processed\\ic-fspml_stock_news_sentiment_processed.csv loaded in 0.04 seconds\n",
      "Concatinating data\n",
      "Done!\n",
      "\n",
      "\n",
      "23:26:11 - Loading file data/processed\\mjw_sotck_tweets_cleaned.csv\n",
      "Date column: post_date\n",
      "File data/processed\\mjw_sotck_tweets_cleaned.csv loaded in 5.44 seconds\n",
      "Concatinating data\n",
      "Done!\n",
      "\n",
      "\n",
      "23:26:17 - Loading file data/processed\\NASDAQ_stock_data_processed.csv\n",
      "Date column: Date\n",
      "File data/processed\\NASDAQ_stock_data_processed.csv loaded in 6.37 seconds\n",
      "Concatinating data\n",
      "Done!\n",
      "\n",
      "\n",
      "23:26:24 - Loading file data/processed\\partner_headlines_cleaned-1.csv\n",
      "Date column: date\n",
      "File data/processed\\partner_headlines_cleaned-1.csv loaded in 1.87 seconds\n",
      "Concatinating data\n",
      "Done!\n",
      "\n",
      "\n",
      "23:26:27 - Loading file data/processed\\partner_headlines_cleaned-2.csv\n",
      "Date column: date\n",
      "File data/processed\\partner_headlines_cleaned-2.csv loaded in 1.92 seconds\n",
      "Concatinating data\n",
      "Done!\n",
      "\n",
      "\n",
      "23:26:30 - Loading file data/processed\\stepahnakkerman_tweets_cleaned.csv\n",
      "Date column: created_at\n",
      "File data/processed\\stepahnakkerman_tweets_cleaned.csv loaded in 4.08 seconds\n",
      "Concatinating data\n",
      "Done!\n",
      "\n",
      "\n",
      "23:26:36 - Loading file data/processed\\tweets_labelled_cleared.csv\n",
      "Error loading file data/processed\\tweets_labelled_cleared.csv\n",
      "\n",
      "\n",
      "23:26:36 - Loading file data/processed\\tweets_remaining_cleared_part1.csv\n",
      "Error loading file data/processed\\tweets_remaining_cleared_part1.csv\n",
      "\n",
      "\n",
      "23:26:36 - Loading file data/processed\\tweets_remaining_cleared_part2.csv\n",
      "Error loading file data/processed\\tweets_remaining_cleared_part2.csv\n",
      "\n",
      "\n",
      "23:26:36 - Loading file data/processed\\tweets_remaining_cleared_part3.csv\n",
      "Error loading file data/processed\\tweets_remaining_cleared_part3.csv\n",
      "\n",
      "\n",
      "23:26:36 - Loading file data/processed\\tweets_remaining_cleared_part4.csv\n",
      "Error loading file data/processed\\tweets_remaining_cleared_part4.csv\n",
      "\n",
      "\n",
      "23:26:36 - Loading file data/processed\\tweets_remaining_cleared_part5.csv\n",
      "Error loading file data/processed\\tweets_remaining_cleared_part5.csv\n",
      "\n",
      "\n",
      "23:26:36 - Loading file data/processed\\tweets_remaining_cleared_part6.csv\n",
      "Error loading file data/processed\\tweets_remaining_cleared_part6.csv\n",
      "\n",
      "\n",
      "23:26:36 - Loading file data/processed\\tweets_remaining_cleared_part7.csv\n",
      "Error loading file data/processed\\tweets_remaining_cleared_part7.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>stock</th>\n",
       "      <th>headline</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>sector</th>\n",
       "      <th>article_headline</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>ZIV_Low</th>\n",
       "      <th>ZIV_Open</th>\n",
       "      <th>ZIV_Volume</th>\n",
       "      <th>ZUMZ_Adj Close</th>\n",
       "      <th>ZUMZ_Close</th>\n",
       "      <th>ZUMZ_High</th>\n",
       "      <th>ZUMZ_Low</th>\n",
       "      <th>ZUMZ_Open</th>\n",
       "      <th>ZUMZ_Volume</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-07 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @permabear_uk: Closing chart: $SPX currentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equinox $EQIX $1b 2024 loan getting punished; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US30 and SPx500 https://t.co/AcbUt6YMq8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @CoinSonarBot: Dow Jones Industrial | 1929 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Horrific Day for @ @Exalted_Trader \\n.\\nTug of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62671 rows × 6912 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date title stock headline ticker name type sector  \\\n",
       "0    2012-01-03 00:00:00   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "1    2012-01-04 00:00:00   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "2    2012-01-05 00:00:00   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "3    2012-01-06 00:00:00   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "4    2012-01-07 00:00:00   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "..                   ...   ...   ...      ...    ...  ...  ...    ...   \n",
       "204           2020-04-09   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "205           2020-04-09   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "206           2020-04-09   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "207           2020-04-09   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "208           2020-04-09   NaN   NaN      NaN    NaN  NaN  NaN    NaN   \n",
       "\n",
       "    article_headline label  ...  ZIV_Low ZIV_Open ZIV_Volume  ZUMZ_Adj Close  \\\n",
       "0                NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "1                NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "2                NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "3                NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "4                NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "..               ...   ...  ...      ...      ...        ...             ...   \n",
       "204              NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "205              NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "206              NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "207              NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "208              NaN   NaN  ...      NaN      NaN        NaN             NaN   \n",
       "\n",
       "     ZUMZ_Close  ZUMZ_High ZUMZ_Low  ZUMZ_Open  ZUMZ_Volume  \\\n",
       "0           NaN        NaN      NaN        NaN          NaN   \n",
       "1           NaN        NaN      NaN        NaN          NaN   \n",
       "2           NaN        NaN      NaN        NaN          NaN   \n",
       "3           NaN        NaN      NaN        NaN          NaN   \n",
       "4           NaN        NaN      NaN        NaN          NaN   \n",
       "..          ...        ...      ...        ...          ...   \n",
       "204         NaN        NaN      NaN        NaN          NaN   \n",
       "205         NaN        NaN      NaN        NaN          NaN   \n",
       "206         NaN        NaN      NaN        NaN          NaN   \n",
       "207         NaN        NaN      NaN        NaN          NaN   \n",
       "208         NaN        NaN      NaN        NaN          NaN   \n",
       "\n",
       "                                                  text  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "204  RT @permabear_uk: Closing chart: $SPX currentl...  \n",
       "205  Equinox $EQIX $1b 2024 loan getting punished; ...  \n",
       "206            US30 and SPx500 https://t.co/AcbUt6YMq8  \n",
       "207  RT @CoinSonarBot: Dow Jones Industrial | 1929 ...  \n",
       "208  Horrific Day for @ @Exalted_Trader \\n.\\nTug of...  \n",
       "\n",
       "[62671 rows x 6912 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup our date range\n",
    "start_date = pd.to_datetime('2012-01-03') \n",
    "end_date = pd.to_datetime('2020-12-31')\n",
    "\n",
    "dt_range = pd.date_range(start_date, end_date)\n",
    "\n",
    "df = pd.DataFrame(dt_range, columns=['date']).sort_values(by=['date'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "for file_path in processed_data_files:\n",
    "    print(\"\\n\")\n",
    "    data = process_agg_file(file_path,subset=0.01)\n",
    "    if data is not None:\n",
    "        print(\"Concatinating data\")\n",
    "        df = pd.concat([df,data],axis=0)\n",
    "        print(\"Done!\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "True     0.999855\n",
       "False    0.000145\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,:].isna().value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DCDC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
